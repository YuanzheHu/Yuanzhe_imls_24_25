{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div width=50% style=\"display: block; margin: auto\">\n",
    "    <img src=\"figures/ucl-logo.svg\" width=100%>\n",
    "</div>\n",
    "\n",
    "### [UCL-ELEC0136 Data Acquisition and Processing Systems 2024]()\n",
    "University College London\n",
    "# Lab 4.2: Data Processing #2 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Objectives\n",
    "The data processing 2 lab focuses on Exploratory Data Analysis (EDA) techniques and addressing data imbalance through fairness postprocessing methods. In particular, we will\n",
    "* Learn how to plot and interpret insights from plots\n",
    "* Briefly cover the steps of (1) data transformation, (2) generating data splits, (3) selecting baseline models and building a classifier\n",
    "* Learn how to produce and evaluate the models for performance and fairness\n",
    "* Learn how to leverage fairness metrics for threshold optimization.\n",
    "\n",
    "\n",
    "### Outline\n",
    "0. Setup\n",
    "1. Data Processing\n",
    "2. Train Baselines and a Classifier (Offline)\n",
    "3. Evaluate and Audit for Fairness the Baselines and the Classifier\n",
    "4. Postprocessing Techniques for Fairness\n",
    "\n",
    "<hr width=70% style=\"float: left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1 Prerequisites\n",
    "This lab uses the following packages:\n",
    "\n",
    "* `folktables`: datasets derived from the American Community Survey (ACS)  Public Use Microdata Sample (PUMS) files which are managed by the US Census Bureau <!-- - more info [here](https://github.com/socialfoundations/folktables)) -->\n",
    "* `scikit-learn`: toolkit for predictive data analysis\n",
    "* `pandas`: data analysis and manipulation toolkit\n",
    "* `matplotlib`: statistical visualization library\n",
    "* `seaborn`: statistical visualization library\n",
    "* `fairlearn`: toolkit for assessing and mitigating an ML system's biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<h4>üë®üèæ‚Äçüíªüë®üèø‚Äçüíª TASK 1: Install Prerequisites</h4>\n",
    "\n",
    "Use the `requirements.txt` file for installing the libraries discussed above.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the following libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data analysis and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Libraries for visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2 Data Acquisition\n",
    "\n",
    "`folktables` offers predefined predictive tasks and the ability to specify the ML problem you want to address. While we won't delve into the thechnical implementation here, the curious minds can explore the details in the `utils/dataset.py` file.\n",
    "\n",
    "In this lab, we specifically focus on **employment status classification** based on 15 input features such as gender, race, marital status, and age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import ACSDataset\n",
    "\n",
    "# Selected target - Employment status record\n",
    "target_task='ESR'\n",
    "\n",
    "# Sensitive group\n",
    "sensitive_group= 'RAC1P'\n",
    "\n",
    "# Pick a state to download data from available_states list.\n",
    "state_list=['CA']\n",
    "\n",
    "# Pick data duration. Available options: [\"1-Year\", \"5-Year\"].\n",
    "duration='1-Year'\n",
    "\n",
    "# Pick data year. Available options: [\"2015\", \"2016\", \"2017\", \"2018\"].\n",
    "year='2018'\n",
    "\n",
    "# Pick data granularity. Available options: [\"person\", \"household\"].\n",
    "granularity= 'person'\n",
    "\n",
    "ACSProblem=ACSDataset(target_task,sensitive_group,state_list,duration,year,granularity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df=ACSProblem.acquire_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Processing  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 (Initial) Data Exploration & Data Cleaning\n",
    "Next we will investigate, analyze and summarize the characteristics of the acquired dataset. This is valuable for\n",
    "\n",
    "1. spotting errors within the dataset;\n",
    "2. grasping data patterns and relationships across variables; and\n",
    "3. identifying outliers or irregular behaviors,\n",
    "\n",
    "and dealing with these issues. \n",
    "\n",
    "First, let's take an initial look at our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset shape (rows,columns)\n",
    "print('Dataset shape (rows,columns) is ', dataset_df.shape)\n",
    "print('\\n')\n",
    "\n",
    "# Get an overview of the dataset by printing the first 10 rows\n",
    "print('Dataset Overview:')\n",
    "dataset_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the index dtype and columns, non-null values and memory usage\n",
    "print('Information about the dataset:')\n",
    "dataset_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<h4>üë©üèº‚Äçüíªüë©üèΩ‚Äçüíª Task 1.1: Deal with erroneous data types</h4>\n",
    "\n",
    "Erroneous data types occur when the format or the categorization of the data type does not align with the intended or expected type for a given attribute or variable. \n",
    "The basic overview of the data above shows that evey column is a numerical.\n",
    "\n",
    "Fix this issue as follows:\n",
    "\n",
    "* Create a function `cast_features(categorical_features: list[str], numerical_features: list[str], data:pd.DataFrame)` that fixes the erroneous datatypes of the dataframe\n",
    "* The function should return a pandas dataframe containing the updated data\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-heading alert-danger\" style=\"background-color: white; border: 2px solid; border-radius: 5px; color: #000; border-color:#AAA; padding: 10px\">\n",
    "<b>üíé Tips</b> \n",
    "\n",
    "* The target should not be part of the input features\n",
    "* Use `ACSProblem.categorical_features` and `ACSProblem.numerical_features` to find the categorical and numerical features of this dataset.\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_features(categorical_features: list[str], numerical_features: list[str], data:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cast features to the correct data type.\n",
    "\n",
    "    Args:\n",
    "        categorical_features (List[str]): list of categorical feature names\n",
    "        numerical_features (List[str]): list of numerical feature names\n",
    "        data (pd.DataFrame): raw dataframe with unprocessed data\n",
    "    Returns:\n",
    "        (pd.DataFrame): a dataframe with the casted features data\n",
    "    \"\"\"\n",
    "    # Add your code here:\n",
    "\n",
    "    # Cast categorical features to `object`\n",
    "    data[categorical_features] = data[categorical_features].astype(\"object\")\n",
    "\n",
    "    # Cast numerical features to `int`\n",
    "    data[numerical_features] = data[numerical_features].astype(\"int\")\n",
    "\n",
    "    return data\n",
    "\n",
    "# Cast feature types\n",
    "df=cast_features(ACSProblem.categorical_features, ACSProblem.numerical_features, dataset_df)\n",
    "\n",
    "# Confirm that the correctness of the datatypes\n",
    "print('Information about the dataset:')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fixed the erroneous data types, let's check for missing values! We will start by identyifying the features with missing values and the quantity of these missing values in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the missing values per column\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our dataset has no missing values, let's move on to generate and review the descriptive statistics of the features and the target. These will help us understand the distribution of both features and the target. Additionally, they will help us determine the most suitable visualization method for each column in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate descriptive statistics about your dataset\n",
    "print('Descriptive statistics for dataset:')\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Exploratory Data Analysis: Visualisations\n",
    "\n",
    "\n",
    "**1. Target distribution visualization**\n",
    "\n",
    "Let's analyze the distribution of samples acfoss each target label. Since our target task (i.e., Employment Status Record - `ESR`) is categorical, an effective method to visualize the target labels is through bar plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a bar plot to visualize the targets\n",
    "df[ACSProblem.target_task].value_counts().sort_values().plot(kind='bar')\n",
    "\n",
    "# Add axes labels\n",
    "plt.ylabel('Number of samples')\n",
    "plt.xlabel('Employment Status Record - ESR')\n",
    "\n",
    "# Show Figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b> Q: What insights can you derive from the bar plot of the target? </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your answer here:\n",
    "\n",
    "# We notice that our dataset is heavily imbalanced with the majority class being the employed class (label=1) \n",
    "# and the minority class representing the unemployed class (label=0). The minority class comprises roughly 12% \n",
    "# of the dataset. We need more insights about the classes that belong to each sensitive group membership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Target and sensitive group distribution visualization**\n",
    "\n",
    "Now, let's see the proportion of the sensitive group (i.e., Race - `RAC1P`) per target label. For simplicity we include the races from the [original paper](https://arxiv.org/abs/2108.04884) here:\n",
    "\n",
    "* 1: White alone\n",
    "* 2: Black or African American alone\n",
    "* 3: American Indian alone\n",
    "* 4: Alaska Native alone\n",
    "* 5: American Indian and Alaska Native tribes specified, or American Indian or Alaska Native, not specified and no other races\n",
    "* 6: Asian alone\n",
    "* 7: Native Hawaiian and Other Pacific Islander alone\n",
    "* 8: Some Other Race alone\n",
    "* 9: Two or More Races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping based on target and sensitive group and plot\n",
    "df.groupby([ACSProblem.target_task, ACSProblem.sensitive_group])[ACSProblem.sensitive_group].count().unstack().plot(\n",
    "    kind=\"bar\", stacked=True)\n",
    "\n",
    "# Add legend\n",
    "plt.legend(title='Race')\n",
    "\n",
    "# Add axes labels\n",
    "plt.ylabel('Number of samples')\n",
    "plt.xlabel('Employment Status Record - ESR')\n",
    "\n",
    "# Show Figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b> Q: What insights can you derive from the bar plot? </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your answer here:\n",
    "# We notice that that the distribution of sensitive groups across each target label is relatively similar.\n",
    "# Additionally, within both the majority and minority target classes, the White race (label=1.0) stands out as the dominant sensitive group, \n",
    "# representing the most significant portion of the data samples.\n",
    "# Finally, we observe that particular sensitive group labels (e.g., 4.0: Alaska Native, 5.0: American Indian and Alaska Native)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<h4>üë©üèæ‚Äçüíªüë®üèª‚Äçüíª Task 2.1: Find an appropriate visualization for the sensitive groups x targets </h4>\n",
    "\n",
    "The previous plot allows to investigate a general trend of the sensitive group allocation on each class, but it does not allow to understand what the exact amount of the underrepresented sensitive groups.\n",
    "\n",
    "* Decide an appropriate plot that allows to effectively display the proportion of each target class per sensitive group. \n",
    "* Create a function `sensitive_group_plot(data:pd.DataFrame, sensitive: str, target: str)` that generates the plot. \n",
    "* The function must both the `Figure` and the `Axis` objects.\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-heading alert-danger\" style=\"background-color: white; border: 2px solid; border-radius: 5px; color: #000; border-color:#AAA; padding: 10px\">\n",
    "    <b>üíé Tip</b>\n",
    "\n",
    "* The folowing plot includes the Race (i.e., `RAC1P`) memberships on x-axis, the amount of the samples with this membership on y-axis and the target category using colors.\n",
    "\n",
    "* This is **not a good visualization because some groups (e.g., group 4 and 5) are not displayed efficiently** (akin to the one above).\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following example is a bad visualisation!!!\n",
    "# Plot a histogram with stacking bars\n",
    "sns.displot(\n",
    "    df,\n",
    "    x=sensitive_group,\n",
    "    hue=ACSProblem.target_task, \n",
    "    kind=\"hist\",\n",
    "    stat=\"count\",\n",
    "    bins=10,\n",
    "    multiple=\"stack\",\n",
    ")\n",
    "\n",
    "# Add axes labels\n",
    "plt.ylabel('Number of samples')\n",
    "plt.xlabel('Race')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-heading alert-danger\" style=\"background-color: white; border: 2px solid; border-radius: 5px; color: #000; border-color:#AAA; padding: 10px\">\n",
    "<b>üíé Tip</b>\n",
    " \n",
    "* Use `ACSProblem.race_labels`, `ACSProblem.sensitive_group` and `ACSProblem.target_task` to find the race labels dictionary, the sensitive group and the target name column, respectively.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitive_group_plot(data:pd.DataFrame, race_labels : list[str], sensitive: str, target: str) -> (plt.Figure, plt.Axes):\n",
    "    \"\"\"\n",
    "    Creates a line plot for each list of data in the given list of data, title and labels.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): dataframe including all the avaible data\n",
    "        race_labels (list[str]): the list of races available in the dataset\n",
    "        sensitive (str): the column name of the sensitive attribute\n",
    "        target (str): the column name of the target task\n",
    "        \n",
    "    Returns:\n",
    "        (plt.Figure, plt.Axes): matplotlib figure and axes objects\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add your code here:\n",
    "\n",
    "    # Create an array with the sensitive group memberships\n",
    "    sens_groups=data[sensitive].unique()\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(20, 30))\n",
    "    for i, ax in zip(sens_groups, axs.ravel()):\n",
    "        data[data[sensitive]==i][target].value_counts().sort_values().plot.bar(ax=ax)\n",
    "        # Set the x-label as title\n",
    "        ax.set_title(race_labels[i])\n",
    "        ax.set_xlabel('')\n",
    "        # Set the y-label\n",
    "        ax.set_ylabel('Number of samples')\n",
    "\n",
    "    return (fig, ax)\n",
    "\n",
    "\n",
    "sensitive_group_plot(df, ACSProblem.race_labels, ACSProblem.sensitive_group, ACSProblem.target_task)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h4>üë®üèΩ‚Äçüíªüë©üèª‚Äçüíª [Optional] TASK 2.2: Input Features Visualisations</h4>\n",
    "\n",
    "* Create a function `histograms(data:pd.DataFrame, categorical_features: list[str])` that will plot a histogram for each of the features in the categorical features of the dataset \n",
    "* The function must return both the `Figure` and the `Axis` objects\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograms(data:pd.DataFrame, categorical_features: list[str], column_name_dic: dict) -> (plt.Figure, plt.Axes):\n",
    "    \"\"\"\n",
    "    Creates a histogram plot for each of the categorical features in the given dataframe.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): dataframe with input features \n",
    "        categorical_features (List[str]): list of categorical feature names\n",
    "    Returns:\n",
    "        (plt.Figure, plt.Axes): matplotlib figure and axes objects\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Add your code here:\n",
    "    fig, axs = plt.subplots(nrows=round(len(categorical_features)/3), ncols=3, figsize=(20, 30))\n",
    "    for i, ax in zip(categorical_features, axs.ravel()):\n",
    "        df[i].value_counts().plot.bar(ax=ax)\n",
    "        # Set the x-label as title\n",
    "        ax.set_title(column_name_dic[i])\n",
    "        ax.set_xlabel('')\n",
    "        # Set the y-label\n",
    "        ax.set_ylabel('Number of samples')\n",
    "\n",
    "    return (fig, ax)\n",
    "\n",
    "histograms(df, ACSProblem.categorical_features, ACSProblem.column_name_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<h4>üßëüèº‚Äçüíªüë©üèø‚ÄçüíªTASK 2.3: Plotting numerical data</h4>\n",
    "\n",
    "* Decide an appropriate plot that allows to effectively display the numerical features and the proportion of each target class \n",
    "* Create a function `numerical_plot(data:pd.DataFrame, numerical_features: list[str])` that produces the plot you picked\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-heading alert-danger\" style=\"background-color: white; border: 2px solid; border-radius: 5px; color: #000; border-color:#AAA; padding: 10px\">\n",
    "<b>üíé Tip</b>\n",
    " \n",
    "*  Use `ACSProblem.numerical_features` and `ACSProblem.target_task` to get the numerical features and the target task of this ML problem.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_plot(data:pd.DataFrame, numerical_features: list[str], target: str):\n",
    "    \"\"\"\n",
    "    Creates a histogram plot for each of the categorical features in the given dataframe.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): dataframe with input features \n",
    "        categorical_features (List[str]): list of categorical feature names\n",
    "        \n",
    "    \"\"\"\n",
    "       \n",
    "    # Add your code here:\n",
    "    # Method 1: Split the age values into 10 bins\n",
    "    # sns.displot(\n",
    "    #     df,\n",
    "    #     x=numerical_features[0],\n",
    "    #     hue=target,\n",
    "    #     kind=\"hist\",\n",
    "    #     stat=\"count\",\n",
    "    #     bins=10,\n",
    "    #     multiple=\"stack\"\n",
    "    # )\n",
    "\n",
    "    # Method 2: Use the kernel density estimate to plot the age distribution per target class\n",
    "    # plt.figure(figsize=(15,8))\n",
    "    \n",
    "    sns.displot(\n",
    "    df, x=numerical_features[0], hue=target,\n",
    "    kind=\"kde\") \n",
    "    \n",
    "numerical_plot(df, ACSProblem.numerical_features, ACSProblem.target_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Data Transformation \n",
    "\n",
    "Since we haven't covered data transformations yet, feel free to consider it a black box and not stress about it. However, if you're curious, you can explore the implementation of the `ACSDataset Class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform data transformation\n",
    "df_trans=ACSProblem.data_transforms(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe transformed data\n",
    "df_trans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train Baselines and a Classifier (Offline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to how we've approached the <b>Data Transformation</b> process, we will handle most of the implementation behind the following steps as black-boxes and we will addresss them in later sessions.\n",
    "\n",
    "<b><span style=\"color: #C0392B\">IMPORTANT NOTE üõë:</span></b> In ELEC0136 week 7, we will learn that during (offline) model training/fitting phase we usually leverage a training set and a validation set. However, `scikit-learn` library does not have build-in support for validation sets. Therefore, in what follows we use only a training set for the (vanilla) training procedure. See more [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Split data into train/test splits\n",
    "First,  let's generate the data splits we are going to use for fitting and evaluating our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data splits\n",
    "train_data, test_data= ACSProblem.generate_splits(df_trans, val_split=False)\n",
    "\n",
    "# Perform column wise partition for each split\n",
    "X_train, sens_train, y_train= ACSProblem.columnwise_partition(train_data)\n",
    "X_test, sens_test, y_test= ACSProblem.columnwise_partition(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Pick a baseline model\n",
    "Next, we pick some simple baseline models that we will use as reference points to evaluate whether the developed model is truly learning patterns and performs better than a random or naive approach. We will use the following baselines:\n",
    "\n",
    "* *Uniformly Random Guess*: Predict the targets with equal probability.\n",
    "* *Prior Random Guess*: Predict 0 or 1 proportional to the prior probability in the dataset.\n",
    "* *Majority Class*: Predict only the the majority/most frequent class, i.e., mode (for our example is class 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import models\n",
    "\n",
    "# Develop the baselines\n",
    "uniform_clf, mode_clf, prior_clf = models.build_baselines(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Pick and train an initial model\n",
    "\n",
    "Let's select logistic regression as our classifier. You can experiment with other models (e.g. an MLP) at a later time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop the logistic regression model\n",
    "LR_clf=models.build_LRModel(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluate and Audit for Fairness the Baselines and the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows we evaluate the performance of the produced baselines and naive model using the following metris:\n",
    "1. Accuracy: measures correct perdictions\n",
    "2. Precision: accuracy of positive predictions\n",
    "3. Recall: measures the ability to correctly identify positive instances\n",
    "4. F1-score: provides a balance between precision and recall, especially when there is an uneven class distribution\n",
    "5. Confusion Matrix:summary of the model's predictions versus the actual classes and includes four metrics: true positive, true negative, false positive, and false negative.\n",
    "6. Demographic Parity Difference: measures the disparity in positive outcomes among sensitive groups.\n",
    "7. Equality of Odds Difference: measures the disparity in true positive and false positive rates across sensitive groups.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for resutls reporting\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score,recall_score, f1_score,ConfusionMatrixDisplay\n",
    "from fairlearn.metrics import equalized_odds_difference, demographic_parity_difference\n",
    "\n",
    "def report_performance(model_list: list[str], X:pd.DataFrame, y:pd.DataFrame, sens:pd.DataFrame):\n",
    "    # Add your code here:\n",
    "\n",
    "    for model in model_list:\n",
    "        y_pred=model.predict(X)\n",
    "        print('-----------------')\n",
    "        print(f\"Performance of {model}\")\n",
    "        print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
    "        print(\"Precision:\", precision_score(y, y_pred))\n",
    "        print(\"Recall:\", recall_score(y, y_pred))\n",
    "        print(\"F1-score:\", f1_score(y, y_pred))\n",
    "        print(\"Confusion Matrix:\", confusion_matrix(y, y_pred))\n",
    "        print(\"Demographic Parity Difference:\", demographic_parity_difference(\n",
    "        y, y_pred, sensitive_features=sens))\n",
    "        print(\"Equalized Odds Difference:\", equalized_odds_difference(\n",
    "        y, y_pred, sensitive_features=sens)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Examine performance on training set\n",
    "report_performance([uniform_clf, mode_clf, prior_clf,LR_clf],X_train,y_train,sens_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Examine performance on test set\n",
    "report_performance([uniform_clf, mode_clf, prior_clf,LR_clf],X_test,y_test,sens_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b> Q: What insights can you derive from the reported metrics for all models? </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your response here:\n",
    "# We notice that the Demographic Parity difference across all model is very low, indicating that all gorups have similar selection rate. \n",
    "\n",
    "# In contrast Equalized Odds difference is very high across all models except the classifier that performs uniformly random guesses. \n",
    "# This suggests that there are significant disparities in predictive performance among different groups and randomly predicting the \n",
    "# employment of an individual is more fair (wrt Equilized Odds) than using the logistic regression classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Postprocessing Techniques for Fairness\n",
    "\n",
    "\n",
    "Since we audited the (naive/initial) logistic regression model for fairness and we noticed that it does not satisfy Equalizes Odds, we are going to enforce this fairness metric as a postprocessing technique. \n",
    "\n",
    "To do so, we are going to use `fairlearn` library's [`ThresholdOptimzer`](https://fairlearn.org/v0.9/api_reference/generated/fairlearn.postprocessing.ThresholdOptimizer.html?highlight=thresholdoptimizer#fairlearn.postprocessing.ThresholdOptimizer) to implement Equality of Opportunity. \n",
    "\n",
    "\n",
    "You can find the original paper introducing Equalized Odds [here](https://proceedings.neurips.cc/paper/2016/file/9d2682367c3935defcb1f9e247a97c0d-Paper.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "\n",
    "def build_EOddFairModel(cls,  X:pd.DataFrame, y:pd.DataFrame, sens:pd.DataFrame):\n",
    "    # Set up ThresholdOptimizer\n",
    "    eo_model = ThresholdOptimizer(\n",
    "        estimator=cls,\n",
    "        constraints=\"equalized_odds\", # Optimize FPR and FNR simultaneously\n",
    "        objective=\"balanced_accuracy_score\", # accuracy_score\n",
    "        grid_size=1000,\n",
    "        flip=False,\n",
    "        prefit=False,\n",
    "        predict_method=\"predict_proba\",\n",
    "    )\n",
    "    \n",
    "    # Adjust the results that the classifier would produce by letting ThresholdOptimizer know what the sensitive features are\n",
    "    eo_model.fit(X, y, sensitive_features=sens)\n",
    "\n",
    "    return eo_model\n",
    "\n",
    "# Postprocess the trained classifier to satisfy Equalized Odds\n",
    "eoFair_clf= build_EOddFairModel(LR_clf,X_train, y_train, sens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine EO-fair classifier on train data\n",
    "y_train_eo= eoFair_clf.predict(\n",
    "    X_train, sensitive_features=sens_train\n",
    ")\n",
    "# Examine EO-fair classifier on test data\n",
    "y_test_eo= eoFair_clf.predict(\n",
    "    X_test, sensitive_features=sens_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Print again report on test set for the previous models\n",
    "report_performance([uniform_clf, mode_clf, prior_clf,LR_clf],X_test,y_test,sens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Print report for this EO-fair classifier\n",
    "\n",
    "print('-----------------')\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_eo))\n",
    "print(\"Precision:\", precision_score(y_test, y_test_eo))\n",
    "print(\"Recall:\", recall_score(y_test, y_test_eo))\n",
    "print(\"F1-score:\", f1_score(y_test, y_test_eo))\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_test, y_test_eo))\n",
    "print(\"Demographic Parity Difference:\", demographic_parity_difference(y_test, y_test_eo, sensitive_features=sens_test))\n",
    "print(\"Equalized Odds Difference:\", equalized_odds_difference(\n",
    "    y_test, y_test_eo, sensitive_features=sens_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices for the EO-fair and initial/naive classifiers \n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,10))\n",
    "\n",
    "ConfusionMatrixDisplay(\n",
    "    confusion_matrix=confusion_matrix(y_test, LR_clf.predict(X_test)), \n",
    "    display_labels=[False, True]).plot(ax=ax[0],cmap=plt.cm.YlGnBu)\n",
    "ax[0].set_title(\"Naive LR\")\n",
    "\n",
    "ConfusionMatrixDisplay(\n",
    "    confusion_matrix=confusion_matrix(y_test, y_test_eo), \n",
    "    display_labels=[False, True],).plot(ax=ax[1],cmap=plt.cm.YlGnBu)\n",
    "ax[1].set_title(\"EO trained LR\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick a dataset and upload it on [Aequitas](http://aequitas.dssg.io/) to generate a bias report!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nyuDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
