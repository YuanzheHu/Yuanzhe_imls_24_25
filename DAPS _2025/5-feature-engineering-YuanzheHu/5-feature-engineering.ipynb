{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div width=50% style=\"display: block; margin: auto\">\n",
    "    <img src=\"figures/ucl-logo.svg\" width=100%>\n",
    "</div>\n",
    "\n",
    "### UCL-ELEC0136 Data Acquisition and Processing Systems 2024\n",
    "University College London\n",
    "# Lab 6: Feature engineering\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "- Gain practical experience of dealing with real-world data\n",
    "- Develop intuition and understanding of how operations on input features can affect model performance, and when to use them\n",
    "- Develop familiarity different methods for assessing feature importance\n",
    "\n",
    "### Outline\n",
    "\n",
    "0. [Setup](#0-setup)\n",
    "1. [Dealing with missing values](#1-dealing-with-missing-values)\n",
    "2. [Transforming the distributions of features](#2-transforming-the-distributions-of-features)\n",
    "3. [Discretising an input feature](#3-discretising-an-input-feature)\n",
    "4. [Feature selection](#4-feature-selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 0. Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Prerequisites\n",
    "First, we need to install the necessary packages for this lab. The packages are:\n",
    "\n",
    "- `ucimlrepo`: real-life datasets for machine learning\n",
    "- `scikit-learn`: statistical machine learning models\n",
    "- `shap`: importance/relevancy metrics\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<h4>üë©‚Äçüíª Task 0.1: Install prerequisites</h4>\n",
    "\n",
    "Install the packages that are required for this lab.\n",
    "\n",
    "<details>\n",
    "<summary>üîé Hint</summary>\n",
    "\n",
    "Remember, there are two steps to adding packages to your `daps` Python environment. You need to:\n",
    "1. **Add the package to the requirements file**.\n",
    "2. **Install all the requirements in the requirements file.**\n",
    "\n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Fetching the dataset\n",
    "\n",
    "We'll be using a dataset containing data from a heart disease study in Cleveland, OH, USA.\n",
    "Using this data, we should be able to predict whether a patient has heart disease, given various measurements that can be taken by a doctor.\n",
    "\n",
    "For a more detailed explanation of the dataset, see [here](https://archive.ics.uci.edu/dataset/45/heart+disease)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import ssl\n",
    "\n",
    "# Ignore ssl certificate verification\n",
    "# We have to do this because in between writing the lab and delivering it, the SSL certificate of the UCIML website expired.\n",
    "# This is a hacky fix. It is terrible practice.\n",
    "# The correct thing to do would be to pester the website owners to update their SSL certificate, but we didn't have time.\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "heart_disease = fetch_ucirepo(id=45) \n",
    "  \n",
    "X = heart_disease.data.features \n",
    "y = heart_disease.data.targets \n",
    "  \n",
    "heart_disease.variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some example inputs\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some example outputs\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `num` is nonzero if the patient has some form of heart disease. We need to encode this to a binary variable (`0` or `1`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<h4>üë©‚Äçüíª Task 0.1: Encode output variable</h4>\n",
    "\n",
    "Modify the `y` DataFrame so that entries are `1` if the patient has some form of heart disease and `0` otherwise.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluating the performance of a model, we need some data that the model hasn't seen. `scikit-learn` provides a handy function for producing a \"test\" (held-out) set, that is only used during evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we should preferably also use a *validation* set, but we're skipping it here for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<h4>üë©‚Äçüíª Task 0.2: Create training and test sets</h4>\n",
    "\n",
    "Using `train_test_split` only, shuffle the `(X, y)` data and split it into a training and a test set, with 80% of the data in the training set.\n",
    "\n",
    "For reproducibility, create a variable, `seed`, and set it to `42`. Use this to set the `random_state` of `train_test_split`. We'll reuse this variable in future to reseed other random processes.\n",
    "\n",
    "Your variable names should be `(X_train, y_train)` and `(X_test, y_test)`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this fails, it means you did something wrong!\n",
    "assert len(X_train) == len(y_train)\n",
    "assert len(X_test) == len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Using a machine learning model\n",
    "\n",
    "In this lab, we'll be using a [*support vector machine*](https://scikit-learn.org/stable/modules/svm.html) classifier. This is a simple but powerful statistical learning model provided by `scikit-learn`.\n",
    "\n",
    "> Understanding the inner workings of this model is not the point of this lab, so we treat it as a black box.\n",
    "\n",
    "We'll demo the SVM here using a **different** dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from models import support_vector_machine\n",
    "\n",
    "# Load the iris dataset\n",
    "X_iris, y_iris = load_iris(return_X_y=True)\n",
    "# Train/test split\n",
    "X_iris_train, X_iris_test, y_iris_train, y_iris_test = train_test_split(X_iris, y_iris, random_state=42)\n",
    "\n",
    "model = support_vector_machine.train(X_iris_train, y_iris_train)\n",
    "support_vector_machine.evaluate(model, X_iris_train, y_iris_train, X_iris_test, y_iris_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the functions we're using: \n",
    "\n",
    "- `support_vector_machine.train` takes in the training data and returns a trained classifier\n",
    "- `support_vector_machine.evaluate` takes in the trained classifier, the training data, and the test data, and prints the score on the training and test sets.\n",
    "\n",
    "In the rest of the lab, you'll see how the performance of the classifier on the **heart disease dataset** can be affected by feature engineering. At each stage, we'll retrain the model on the feature-engineered data and see how it performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 1. Dealing with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do when receiving data is to check whether there are any missing values.\n",
    "\n",
    "As `X_train` is a `pd.DataFrame`, we can use the `isna` (short for \"is not applicable\" or \"is not a number\") method to generate a table that has `0` where the values are present, and `1` if the values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "help(pd.DataFrame.isna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-heading alert-danger\" style=\"background-color: white; border: 2px solid; border-radius: 5px; color: #000; border-color:#AAA; padding: 10px\">\n",
    "    <b>üíé Tip</b>\n",
    "\n",
    "- *Methods* are like functions that 'belong' to a specific object.\n",
    "- In the output of the `help` command above, there's an example of using the `isna` method of a `pd.DataFrame` object.\n",
    "- In `pandas`, you can often chain together methods on DataFrames in one line, like this:\n",
    "  ```python\n",
    "  X_train.sum().max()\n",
    "  ```\n",
    "- You might want to have the DataFrame documentation page open so that you can easily find any methods you need - this section should be solved using DataFrame methods alone (i.e., without manually iterating over rows in the data).\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<h4>üë©‚Äçüíª Task 1.1: Compute the percentage of missing values</h4>\n",
    "\n",
    "Using methods of the `X_train` DataFrame, compute the percentage of missing values for each input feature.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing values seem to only occur in two input features, and are missing in only a small amount of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<h4>üë©‚Äçüíª Task 1.2: Deal with the missing values</h4>\n",
    "\n",
    "For each feature that has missing values:\n",
    "\n",
    "- Visualise the distribution of the values for that feature using a bar chart\n",
    "  - Remember to label your axes\n",
    "  - [Optional] If you like, you could also display bars for the NaN entries, which allows you to compare their frequency with the other categories\n",
    "- Select a method for dealing with the missing values, and **justify your answer in the Q/A box below**. Also explain why one *other* method would be **unsuitable**.\n",
    "- Implement your solution, and evaluate it using `evaluate`\n",
    "  - Your solution should modify `X_train`, `y_train`, `X_test`, and `y_test`\n",
    "  - Remember, **imputing missing values in the test set must only be done using information from the training set!**\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-heading alert-danger\" style=\"background-color: white; border: 2px solid; border-radius: 5px; color: #000; border-color:#AAA; padding: 10px\">\n",
    "    <b>üíé Tip</b>\n",
    "\n",
    "- Create a copy of the unmodified dataframes so that if you make a mistake you don't have to re-run the notebook from the beginning!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: What method(s) will you use for dealing with the missing values? Why?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A:** *add your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: What is an unsuitable method for dealing with the missing values? Why?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A:** *add your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 2. Transforming the distributions of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many statistical classifiers work best if the distribution of each input feature follows a Gaussian distribution.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<h4>üë©‚Äçüíª Task 2.1: Visualising feature distributions</h4>\n",
    "\n",
    "- Using `matplotlib`, make a figure comprised of a subplot grid with 2 rows and 7 columns\n",
    "- On each subplot, plot the **histogram** of one of the input features\n",
    "- Which of the continuous variables appear to be **not** Gaussian-distributed? Write your answer in the Q/A box.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-heading alert-danger\" style=\"background-color: white; border: 2px solid; border-radius: 5px; color: #000; border-color:#AAA; padding: 10px\">\n",
    "    <b>üíé Tip</b>\n",
    "\n",
    "- If your figure has overlapping labels or looks a bit squashed, try using `plt.tight_layout()` at the end of the cell.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Which of the continuous variables are not Gaussian distributed?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A:** *add your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<h4>üë©‚Äçüíª Task 2.2: Transforming the distributions </h4>\n",
    "\n",
    "- `scipy` provides an implementation of the Yeo-Johnson transformation. Find it (via your favourite search engine) and use it to transform the variables you identified above.\n",
    "- Evaluate the model on the transformed data, and compare to the scores on the untransformed data.\n",
    "- How have the scores of the model on the training and test set changed? Have we improved the model's ability to generalise? How do you know? Write your answer in the Q/A box.\n",
    "- Visualise histograms of the transformed distributions\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-heading alert-danger\" style=\"background-color: white; border: 2px solid; border-radius: 5px; color: #000; border-color:#AAA; padding: 10px\">\n",
    "    <b>üíé Tip</b>\n",
    "\n",
    "- Create a copy of the unmodified dataframes so that if you make a mistake you don't have to re-run the notebook from the beginning.\n",
    "- Remember to re-train the model on the transformed data using `support_vector_machine.train`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: How have the scores of the model on the training and test set have changed? Have we improved the model's ability to generalise? How do you know?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**: *add your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 3. Discretising an input feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we might want to turn a continuous feature into a discrete one. Sometimes, this is necessary, as some models only work with discrete inputs. Other times, we might find that discretisation improves the model's performance, as it helps it to generalise better.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<h4>üë©‚Äçüíª Task 3.1: Discretising a continuous feature</h4>\n",
    "\n",
    "- The values in the transformed `thalach` column are high resolution and vary over a large range. This means that they might benefit from being discretised!\n",
    "- Plot a **cumulative density histogram** of the values in the `thalach` column of the training data.\n",
    "- Pandas provides `qcut`, a function for discretising a DataFrame based on quantiles (i.e., ensuring that each bin has a similar count). It also provides `cut`, a function for discretising based on predefined bin edges. Using these functions, discretise the `thalach` column into **10 bins**. The bin edges should be such that each bin has a similar count. Your final code should modify both training and test DataFrames.\n",
    "- Evaluate the performance of the model with a continuous `thalach` column and with a discretised `thalach` column.\n",
    "- Plot a bar chart of the binned `thalach` data.\n",
    "- In the Q/A box, explain why this discretisation has improved the model's performance.\n",
    "\n",
    "<details>\n",
    "    <summary>üîé Hint</summary>\n",
    "    You can plot a cumulative density histogram by supplying additional keyword arguments to the standard histogram function.\n",
    "    </details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-heading alert-danger\" style=\"background-color: white; border: 2px solid; border-radius: 5px; color: #000; border-color:#AAA; padding: 10px\">\n",
    "    <b>üíé Tip</b>\n",
    "\n",
    "- Use data with no NaNs, and with Yeo-Johnson transformed variables.\n",
    "- Remember, you can't use statistical properties of the test set when transforming the test data points.\n",
    "- For the model we are using, the bin labels must be integers (for example, you could use `0` to represent `thalach < X`, `1` to represent `X < thalach < Y`, and so on).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Why has discretising <code>thalach</code> improved the model's performance?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A:** *add your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 4. Feature selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, our goal is to reduce the number of inputs that the model requires to make a prediction, without losing too much performance. In fact, as we'll see, sometimes selecting only the most relevant features can even *boost* performance.\n",
    "\n",
    "We want to select **5** input features, from the 13 possible candidates. We explore a few methods for identifying the most important features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Using mutual information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` provides `mutual_info_classif` to approximate the mutual information criterion for classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "help(mutual_info_classif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<h4>üë©‚Äçüíª Task 4.1: Identifying important features using mutual information</h4>\n",
    "\n",
    "- Compute the mutual information criterion for the training data using `mutual_info_classif`. Set the `random_state` parameter to the `seed` variable you defined before.\n",
    "- Plot a bar chart of the results, where the x-axis labels are column names and the y-axis values are the mutual information between each column and the output variable.\n",
    "- In the Q/A box, write the column names of the 5 features with highest mutual information with the output.\n",
    "- Evaluate the model with all 13 features, and with only the top 5 mutual information features. **Has the performance of the model improved, stayed the same, or got worse? What does that tell us about the feature importance?** Answer in the Q/A box.\n",
    "- Why might a model improve when the number of input features is reduced? Answer in the Q/A box.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-heading alert-danger\" style=\"background-color: white; border: 2px solid; border-radius: 5px; color: #000; border-color:#AAA; padding: 10px\">\n",
    "<b>üíé Tip</b>\n",
    "\n",
    "- Use the model that has been trained on the data with no NaNs, Yeo-Johnson transformed variables, and binned `thalach`.\n",
    "- You can use `np.argsort(A)` to get the indices that would sort an array `A`. The indices can then be used to get a sorted version of something else.\n",
    "- If you get a warning from `sklearn`, replace `y_train` with `np.ravel(y_train)`. This simply flattens the `y_train` array, to ensure that it's 1D.\n",
    "- For this section, don't modify or overwrite any of the DataFrames! Create new copies, instead.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: What are the 5 columns with the highest mutual information with the output?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**: *add your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Has the model performance improved, stayed the same, or got worse? What does that tell us about the feature importance?</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**: *add your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Why might a model improve when the number of features is reduced?</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**: *add your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP is a Python package for computing *Shapley values*, which are an idea from game theory. The basic principle is to **allocate credit for a model‚Äôs output among its input features**. Hence, for a given output prediction, we can gain insight into **which input features** contributed to the prediction.\n",
    "\n",
    "SHAP is a hugely powerful tool, as you can apply it to any machine learning model (even LLMs!) to provide a greater degree of interpretability. However, not many people have heard of it. If you're interested, there's some really cool theory behind it [[paper](https://arxiv.org/abs/1705.07874)].\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<h4>üë©‚Äçüíª Task 4.2: Identifying important features using Shapley additive values (SHAP)</h4>\n",
    "\n",
    "- Using `shap.utils.sample`, generate a subset of 100 points from the training set to act as 'background data'. Ideally, we'd use the full training set, but it gets quite slow to compute, so we use a subset for this lab.\n",
    "- Create a SHAP explainer object using `shap.KernelExplainer`, your background data, and the class probability prediction function from our model (stored in `model.predict_proba`).\n",
    "- Run the explainer on the test set, storing the result in a variable called `shap_values`.\n",
    "- Using `shap.plots.bar`, visualise the average SHAP absolute values. What are the top 5 features according to SHAP? Does SHAP agree with the mutual information criterion? Answer in the Q/A box.\n",
    "- Has the model performance improved, stayed the same, or got worse? What does that tell us about the feature importance?  Answer in the Q/A box.\n",
    "<details>\n",
    "<summary>üîé Hint</summary>\n",
    "If you're stuck, see whether you can find anything helpful on <a href=https://github.com/shap/shap#sample-notebooks>SHAP's Git repo</a>.\n",
    "</details>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-heading alert-danger\" style=\"background-color: white; border: 2px solid; border-radius: 5px; color: #000; border-color:#AAA; padding: 10px\">\n",
    "<b>üíé Tip</b>\n",
    "\n",
    "- Use the model that has been trained on the data with no NaNs, Yeo-Johnson transformed variables, and binned `thalach`.\n",
    "- **Remember to set the random state of the `sample()` function to the `seed` variable from before.**\n",
    "- Computing SHAP values takes a minute or so, so why not watch [this explanation](https://www.youtube.com/watch?v=MQ6fFDwjuco) of what's going on while your code is running.\n",
    "- The exact choice of SHAP explainer that you use depends on the model that you want to explain. As the model we're using (nonlinear support vector machine) can be formulated using kernels, we use a `KernelExplainer`. Don't worry if none of those words mean anything to you, it's not important for this course.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "# Sample 100 datapoints as \"background data\"\n",
    "# Add your code here:\n",
    "\n",
    "# Create a SHAP explainer\n",
    "# Add your code here:\n",
    "\n",
    "# Evaluate the explainer on the test set\n",
    "# Add your code here:\n",
    "\n",
    "# shap_values is an array of shape (n_samples, n_features, n_outputs)\n",
    "# Confusingly, although we only have binary outcomes (1 or 0), SHAP still returns 2 outputs\n",
    "# The output at index 1 is the probability that the patient has heart disease\n",
    "shap_values = shap_values[:, :, 1]\n",
    "\n",
    "# Plot the SHAP values\n",
    "# Add your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: What are the top 5 features according to SHAP? Does SHAP agree with the mutual information criterion?</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A:** *add your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Has the model performance improved, stayed the same, or got worse? What does that tell us about the feature importance?</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**: *add your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h4>üë©‚Äçüíª [Optional] Task 4.2b: Explaining single predictions with SHAP waterfall plots</h4>\n",
    "\n",
    "SHAP can also be used to understand why the model predicted a particular output class for a particular input.\n",
    "\n",
    "Using `shap.plots.waterfall`, compare 3 candidates (2 from the same class, and one from the other class). Draw some comparisons between them. For each patient, what are the most significant features? How sure is the model of its predictions?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Q: What are some similarities and differences between the patients? What are the most significant features? How sure is the model of its predictions?</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**: *add your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Using principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're not limited to keeping the input features in the same geometrical space that they came in. In fact, there might be a way of projecting the data onto another co-ordinate system where their influence is easier to separate.\n",
    "\n",
    "One method for doing this is *principal component analysis* (PCA), a concept from linear algebra. PCA effectively involves computing the eigenvalues and eigenvectors of the input data, and then using these as the new co-ordinate basis. In pictures, that looks something like this:\n",
    "\n",
    "![PCA in 2D](figures/pca.png)\n",
    "\n",
    "By only keeping the eigenvectors corresponding to the largest eigenvalues, we end up with a reduced set of input coordinates that should explain most of the data.\n",
    "\n",
    "If you're interested in more detail, check out [this excellent tutorial](https://setosa.io/ev/principal-component-analysis/), which is the source of the above figure.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<h4>üë©‚Äçüíª Task 4.3 Identifying important (transformed) features using PCA</h4>\n",
    "\n",
    "- Scikit-learn provides a PCA function. Find its documentation and use it to compute the first 5 principal components of the training data. Transform the training and test data with these components.\n",
    "- Compare the model performance with only the first 5 principal components and the whole data. How does the performance compare to the mutual information and SHAP methods? Answer in the Q/A box. \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: How does the PCA performance compare to the mutual information and SHAP methods?</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**: *add your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h4>üë©‚Äçüíª [Optional] Task 4.3b: Quantifying the effect of more principal components</h4>\n",
    "\n",
    "- With PCA, we can compute how well a given set of principal components represents the data.\n",
    "- Create a plot showing how the percentage of variance explained by the principal components changes as the number of components is increased from 0 to 13.\n",
    "\n",
    "<details>\n",
    "<summary>üîé Hint</summary>\n",
    "The PCA object has a property that might be useful in computing the explained variance. The easiest way of generating the plot is with a loop.\n",
    "</details>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<h4>üë©‚Äçüíª Task 4.4: Reviewing the results</h4>\n",
    "\n",
    "- What are the strengths and weaknesses of the feature selection methods we've discussed in this section? Answer in the Q/A box below.\n",
    "- Your answer should include reference to the **real-world scenario** of this dataset.\n",
    "- Also consider how the methods are affected by any sources of **randomness**, and how they deal with **correlated features**.\n",
    "</div>\n",
    "<div class=\"alert alert-heading alert-danger\" style=\"background-color: white; border: 2px solid; border-radius: 5px; color: #000; border-color:#AAA; padding: 10px\">\n",
    "<b>üíé Tip</b>\n",
    "\n",
    "- You might have to carefully revisit the documentation for `mutual_info_classif` to spot how randomness plays a role in this method.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: What are the strengths and weaknesses of the feature selection methods we've discussed in this section?</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**: *add your answer here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
